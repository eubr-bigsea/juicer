FROM ubuntu:18.04 as base

LABEL maintainer="Vinicius Dias <viniciusvdias@dcc.ufmg.br>, Guilherme Maluf <guimaluf@dcc.ufmg.br>, Walter Santos <walter@dcc.ufmg.br>"

ENV JUICER_HOME /usr/local/juicer
ENV JAVA_HOME /usr/lib/jvm/java-8-openjdk-amd64
ENV PATH="${PATH}:${JAVA_HOME}"
ENV TERM=xterm\
    TZ=America/Sao_Paulo\
    DEBIAN_FRONTEND=noninteractive

RUN apt-get update && apt-get install -y \ 
      python3.7-dev \
      python3-pip \
      python3-dev \
      python3-tk \
      python3-setuptools \
      openjdk-8-jdk \
      curl \
      graphviz \
      locales \
      libffi-dev \
  && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.7 2 \
  && update-alternatives --install /usr/bin/python python /usr/bin/python3 1 \
  && update-alternatives --install /usr/bin/pip pip /usr/bin/pip3 1\
  && sed -i -e 's/# en_US.UTF-8 UTF-8/en_US.UTF-8 UTF-8/' /etc/locale.gen \
  && locale-gen \
  && update-locale LANG=en_US.UTF-8 \
  && echo "LANG=en_US.UTF-8" >> /etc/default/locale \
  && echo "LANGUAGE=en_US.UTF-8" >> /etc/default/locale \
  && echo "LC_ALL=en_US.UTF-8" >> /etc/default/locale \
  && rm -rf /var/lib/apt/lists/*

ENV LC_ALL en_US.UTF-8
ENV LANG en_US.UTF-8
ENV LANGUAGE en_US.UTF-8

ENV HADOOP_VERSION_BASE=2.7.7
ENV HADOOP_HOME /opt/hadoop-${HADOOP_VERSION_BASE}
ENV ARROW_LIBHDFS_DIR $HADOOP_HOME/native
ENV LD_LIBRARY_PATH=$HADOOP_HOME/native:$LD_LIBRARY_PATH
ENV HADOOP_CONF_DIR $HADOOP_HOME/etc/hadoop

RUN curl -sL https://archive.apache.org/dist/hadoop/core/hadoop-${HADOOP_VERSION_BASE}/hadoop-${HADOOP_VERSION_BASE}.tar.gz | tar -xz -C /opt/


# Spark 2.3.2 (HDP ecossystem)
# hdp-spark2.tar.gz is generated by copying the spark binaries (available in folders like /usr/hdp/current/ or /opt/spark2). In our case was /opt/spark2, but if you have another directory, you must change some parameters bellow.
# This approach requires that both files, hdfs-site.xml and core-site.xml, be available in hadoop config folder (that can be done in docker-compose).

ENV HDP_VERSION 3.1.5.0-152
ENV SPARK_HOME /opt/spark2

RUN tar -xf hdp-spark2.tar.gz -C /opt/ && rm hdp-spark2.tar.gz && \
	mv ${SPARK_HOME}/conf/etc/spark2/${HDP_VERSION}/0/* ${SPARK_HOME}/conf/ && \
    mkdir -p ${SPARK_HOME}/jars/hwc && \
	mv ${SPARK_HOME}/jars/hive-warehouse-connector-assembly-1.0.0.${HDP_VERSION}.jar /opt/spark2/jars/hwc/ && \
    mv ${SPARK_HOME}/jars/pyspark_hwc-1.0.0.${HDP_VERSION}.zip ${SPARK_HOME}/jars/hwc/ && \
	sed -i 's/spark\.eventLog\.enabled true/spark\.eventLog\.enabled false/g' ${SPARK_HOME}/conf/spark-defaults.conf && \
	sed -i 's/spark\.driver\.extraLibraryPath \/usr\/hdp\/current\/spark2-client\/jars/spark\.driver\.extraLibraryPath  \/opt\/spark2\/jars\/hwc\/hive-warehouse-connector-assembly-1\.0\.0\.3\.1\.5\.0-152\.jar/' ${SPARK_HOME}/conf/spark-defaults.conf && \
	mkdir -p /opt/anaconda3/bin && \
	ln -s /etc/alternatives/python3 /opt/anaconda3/bin/python3.7 


WORKDIR $JUICER_HOME
COPY requirements.txt $JUICER_HOME

RUN pip3 install -U pip wheel
RUN python -m pip install -r $JUICER_HOME/requirements.txt --no-cache-dir

COPY . $JUICER_HOME
RUN pybabel compile -d $JUICER_HOME/juicer/i18n/locales

ENV PYTHONPATH $JUICER_HOME:$SPARK_HOME/python:${SPARK_HOME}/python/lib/pyspark.zip:${SPARK_HOME}/python/lib/py4j-*.zip
ENV PATH=$PATH:$HADOOP_HOME/bin

COPY ./entrypoint.sh /opt/
RUN mkdir -p /usr/local/juicer/jars/ && ln -s $HADOOP_HOME /opt/hadoop
RUN curl -Lo $JUICER_HOME/jars/spark-lof_2.11-1.0.jar https://github.com/dccspeed/spark-lof/raw/master/dist/spark-lof_2.11-1.0.jar
RUN curl -Lo $JUICER_HOME/jars/lemonade-spark-ext-1.0.jar https://github.com/eubr-bigsea/lemonade-spark-ext/raw/master/dist/lemonade-spark-ext-1.0.jar

RUN echo "export CLASSPATH=$(hadoop classpath --glob):/usr/local/juicer/jars/spark-lof_2.11-1.0.jar:/usr/local/juicer/jars/lemonade-spark-ext-1.0.jar" >> /etc/profile.d/juicer.sh && \
    echo "export HADOOP_HOME=$HADOOP_HOME" >> /etc/profile.d/juicer.sh && \
    echo "export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop" >> /etc/profile.d/juicer.sh && \
    echo "export PYSPARK_PYTHON=/opt/anaconda3/bin/python3.7" >> /etc/profile.d/juicer.sh && \
    chmod a+x /etc/profile.d/juicer.sh

ENTRYPOINT ["/opt/entrypoint.sh"]
