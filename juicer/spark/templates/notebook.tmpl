{
  {%- set all_tasks = [] %}
  {%- for instance in instances %}
  {%- if instance.has_code and instance.enabled %}
  {%- do all_tasks.append(instance) %}
  {%- endif %}
  {%- endfor %}
  "cells" : [
    {
      "cell_type" : "markdown",
      "metadata": {},
      "source" : [
        "# {{workflow_name}}\n",
        "Generated by {{user.name}} at {{ now.strftime('%Y/%m/%m %H:%M:%S') }}\n",
        "\n",
        "This code was generated by [Lemonade](http://www.lemonade.org.br), a tool for design data processing and machine learning workflows.\n",
        "Targeting platform is Apache Spark. In order to be able to run this notebook, you must:\n",
        "1. Install all dependencies for Lemonade;\n",
        "2. Configure connection parameters for Apache Spark and HDFS;\n",
        "3. Review the code and make any necessary adjust.\n",
        "\n",

        "## Configuring Apache Spark and HDFS\n",
        "\n",

        "## Installing dependencies\n",
        "Lemonade requires Python 2.7. Dependencies can be installed by using the command `pip`. If you do not know how to use id, check ...\n",
        "\n",
        "\n",
        "`pip install pyspark scipy matplotlib`\n",

        "\n",
        "## Jupyter setup \n",
        "The easiest way to use Jupyter with PySpark is to define driver's environment variables. Add these lines to your `~/.bashrc` or `~/.zshrc` file:\n",
        "\n`\n",
        "export PYSPARK_DRIVER_PYTHON=jupyter\n",
        "export PYSPARK_DRIVER_PYTHON_OPTS='notebook'\n",
        "`\n\n",
        "Also, if you are using a Python virtual environment (recommended), install and configure a kernel:",
        "\n\n",
        "`pip install ipykernel\n",
        "ipython kernel install --user --name=lemonade\n",
        "`\n\n",
        "Restart your terminal, close the notebook (if opened) and launch PySpark again:\n",
        "\n",
        "`pyspark`\n",
        "\n",
        "**Do not** forget to change the kernel to the new one (`lemonade`) in Jupyter \n",
        "## tl;dr\n",
        "\n`\n",
        "$ export PYSPARK_DRIVER_PYTHON=jupyter\n",
        "$ export PYSPARK_DRIVER_PYTHON_OPTS='notebook'\n",
        "$ python -m venv lemonade\n",
        "$ source lemonade/bin/activate\n",
        "(venv) $ pip install ipykernel\n",
        "(venv) $ ipython kernel install --user --name=lemonade\n",
        "(venv) pyspark\n",
        "`\n\n"

      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
        "metadata": {
          "collapsed": true
        },
        "source": [
            "# Not all imports are really necessary, remove them accordingly.\n",
            "from concurrent.futures import ThreadPoolExecutor\n",
            "import collections\n",
            "import datetime\n",
            "import itertools\n",
            "import json\n",
            "import os\n",
            "import re\n",
            "import simplejson\n",
            "import string\n",
            "import sys\n",
            "import time\n",
            "import threading\n",
            "import traceback\n",
            "import unicodedata\n",
            "import juicer.spark.ext as juicer_ext\n",
            "\n",
            "from gettext import gettext as _\n",
            "from IPython.display import display, HTML\n",
            "from textwrap import dedent\n",
            "from timeit import default_timer as timer\n",
            "\n",
            "from pyspark.ml import classification, evaluation, feature, tuning, clustering\n",
            "from pyspark.ml.linalg import Vectors\n",
            "from pyspark.sql import functions, types, Row, DataFrame\n",
            "from pyspark.sql.utils import IllegalArgumentException\n",
            "from pyspark.sql.window import Window\n",
            "from pyspark.ml.linalg import Vectors, VectorUDT\n",
            "\n",
            "from pyspark.ml import Pipeline\n",
            "from pyspark.ml.classification import *\n",
            "from pyspark.ml.clustering import *\n",
            "from pyspark.ml.evaluation import *\n",
            "from pyspark.ml.feature import *\n",
            "from pyspark.ml.tuning import *\n",
            "from pyspark.ml.recommendation import *\n",
            "from pyspark.ml.regression import *\n",
            "from pyspark.mllib.evaluation import *\n",
            "from juicer import privaaas\n",
            "from juicer.util import dataframe_util \n",
            "from juicer.spark.reports import *\n",
            "from juicer.spark.ml_operation import ModelsEvaluationResultList\n"
        ],
        "outputs": []
    },
    {
          "cell_type": "code",
          "execution_count": null,
          "metadata": {
            "collapsed": true
          },
          "source": [
                "def emit_event(*args, **kwargs):\n",
                "    \"\"\" Display results \"\"\"\n",
                "    if kwargs.get('type') == 'IMAGE':\n",
                "        v = HTML('<img src=\"data:image/png;base64,{}\"/>'.format(kwargs.get('message')))\n",
                "    elif 'message' in kwargs:\n",
                "        v = HTML(kwargs['message'])\n",
                "    else:\n",
                "        v = HTML(kwargs)\n",
                "    display(v)\n",
                "    return v\n"
          ],
          "outputs": []
    },
    {
          "cell_type": "markdown",
          "metadata": {
            "collapsed": true
          },
          "source": [
                "### Spark configuration \n",
                "Please, update the Spark configuration in next cell, specifying a master."
          ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true
      },
      "source": [
            "from pyspark.sql import SparkSession\n",
            "spark_session = SparkSession.builder \\\n",
            "    .master(\"local\") \\\n",
            "    .appName(\"{{workflow_name}}\") \\\n",
            "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
            "    .getOrCreate()\n"
      ],
      "outputs": []
    }
    {%-if all_tasks|length %},{% endif %}
    {%- for instance in all_tasks %}
    {%- set task = instance.parameters.task %}
    {%- set task_id = task.id %}
    {
      "cell_type" : "code",
      "execution_count": null,
      "metadata" : {
            "collapsed" : true
      },
      "source" : [
        {%- if task.forms.comment and task.forms.comment.value %}
        {{('# ' + task.forms.comment.value.strip().replace('"', '') + "\n") |tojson }},
        "\n",
        {%- endif %}
        "task_id = '{{task_id}}'\n",
        {%- for line in instance.generate_code().strip().split('\n') %}
        {{(line + "\n") | tojson}},
        {%- endfor %}
        "\n"
        {%- if instance.contains_results() %},
        "results = {\n",
            {%- for port_name,out in zip(task.port_names, instance.get_output_names(',').split(',')) %}
            {%- if port_name and out %}
            "    '{{port_name}}': {{out}},\n",
            {%- endif %}
            {%- endfor %}
            "    'task_id': task_id\n",
        "}\n",
        "df_types = (DataFrame, dataframe_util.LazySparkTransformationDataframe)\n",
        "outputs = [(name, out) for name, out in results.items()\n",
        "    if isinstance(out, df_types)]\n",
        {%- if instance.has_code and instance.enabled and instance.contains_sample %}
        "for name, out in outputs:\n",
        "    display(dataframe_util.emit_sample(task_id, out, emit_event, name))\n"
        {%- if instance.has_code and instance.enabled and instance.contains_schema %},{% endif %}
        {%- endif %}
        {%- if instance.has_code and instance.enabled and instance.contains_schema %}
        "for name, out in outputs:\n",
        "    display(dataframe_util.emit_schema(task_id, out, emit_event, name))\n"
        {%- endif %}
        {%- endif %}
      ],
      "outputs": []
    }{%-if not loop.last%},{% endif %}
    {%- endfor %}
  ],
  "metadata": {
       "kernelspec": {
         "display_name": "lemonade",
          "language": "python",
          "name": "lemonade"
      },
      "language_info": {
        "codemirror_mode": {
          "name": "ipython",
          "version": 2
        },
        "file_extension": ".py",
        "mimetype": "text/x-python",
        "name": "python",
        "nbconvert_exporter": "python",
        "pygments_lexer": "ipython2",
        "version": "2.7.12"
      }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}